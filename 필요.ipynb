{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1d7caf-273f-4bed-b544-185b79ebe1ad",
   "metadata": {},
   "source": [
    "# 선형회귀(최소제곱법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e733567-4ee6-4b34-9055-e81d5b1d5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산을 위한 형변환(Pandas Series => np.array)\n",
    "X = np.array(df['x']).reshape(-1, 1)\n",
    "y = np.array(df['y']).reshape(-1, 1)\n",
    "# print(X, type(X), end = '\\n\\n')\n",
    "# print(y, type(y))\n",
    "\n",
    "# 절편에 의해 x와 w의 개수가 다르므로 행렬 연산을 위해 x의 1열에 1을 가가\n",
    "X = np.hstack((X ** 0, X))\n",
    "\n",
    "# 최소제곱법 적용 => 만약 X, y를 np.matrix형으로 바꿔준다면 조금 더 쉽게 가능\n",
    "w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(f\"parameter : {w}\")\n",
    "\n",
    "# 예측 데이터를 시각화하기 위해 x의 범위를 설정하고 이를 이용해서 직선 생성\n",
    "xp = np.arange(-2, 1, 0.01)\n",
    "yp = w[0, 0] + w[1, 0] * xp\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize = (6, 4))\n",
    "plt.scatter(df.x, df.y, label = 'Training Data')\n",
    "plt.plot(xp, yp, 'r', label = 'Predict Data')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a543f-14c7-4954-9bad-ffaa34b0c25d",
   "metadata": {},
   "source": [
    "# 비선형 회귀(최소제곱법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314e642-0e97-4273-97c6-c333c860d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산을 위한 형변환(Pandas Series => np.array)\n",
    "X = np.array(df['x']).reshape(-1, 1)\n",
    "y = np.array(df['y']).reshape(-1, 1)\n",
    "xp = np.arange(-4.5, 4.5, 0.01).reshape(-1, 1)\n",
    "# print(X, type(X), end = '\\n\\n')\n",
    "# print(y, type(y))\n",
    "\n",
    "# 그래프 구역 별로 나누기\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 차수에 따른 예측함수를 구하기 위해 반복시행\n",
    "for degree in range(1, 11):\n",
    "    polybasis = np.hstack([xp** j for j in range(degree + 1)]) # 차수에 따른 테스트 데이터 생성\n",
    "    \n",
    "    A = np.hstack([X ** j for j in range(degree + 1)]) # 차수에 따른 훈련 데이터 생성\n",
    "    w = np.linalg.inv(A.T @ A) @ A.T @ y # 최소제곱법으로 w 구하기\n",
    "    yp = polybasis @ w # 구한 w와 테스트 데이터로 예측함수 구기기\n",
    "    print(f\"{degree}차 파라미터 : {w}\", end = '\\n\\n')\n",
    "\n",
    "    # 시각화\n",
    "    ax = axes[degree-1]\n",
    "    ax.plot(X, y, 'bo', label='Training Data')\n",
    "    ax.plot(xp, yp, 'r', label='Predict Data')\n",
    "    ax.set_title(f'Degree {degree}')\n",
    "    ax.set_xlim(-2, 1)    \n",
    "    ax.set_ylim(-30, 20)\n",
    "    ax.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3edff0d-d8ab-467f-a512-7bc16368ed7f",
   "metadata": {},
   "source": [
    "# 선형회귀(경사하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ac2de-ab02-4145-89e1-0a7769030f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산을 위한 형변환(Pandas Series => np.array)\n",
    "X = np.array(df['x']).reshape(-1, 1)\n",
    "y = np.array(df['y']).reshape(-1, 1)\n",
    "# print(X, type(X), end = '\\n\\n')\n",
    "# print(y, type(y))\n",
    "\n",
    "# 파라미터의 초기값, 에포크, 학습률 설정\n",
    "w1, w0 = 0, 0\n",
    "lr = 0.001\n",
    "epoch = 500\n",
    "n = float(len(X))\n",
    "\n",
    "# 설정한 에포크만큼 반복시행\n",
    "for _ in range(epoch):\n",
    "    y_pred = w0 + w1 * X # 예측함수 정의\n",
    "    w0 -= lr * (1 / n) * sum(y_pred - y) # w0 업데이트\n",
    "    w1 -= lr * (1 / n) * sum(X * (y_pred - y)) # w1 업데이트\n",
    "print(f\"Parameter : {w0, w1}\")\n",
    "\n",
    "# 테스트 데이터, 예측 데이터 생성\n",
    "xp = np.arange(-2, 1, 0.01)\n",
    "yp = w0 + w1 * xp\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize = (6, 4))\n",
    "plt.scatter(df.x, df.y, label = 'Training Data')\n",
    "plt.plot(xp, yp, 'r', label = 'Predict Data')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7990296-2e2f-4d6c-ac8f-fde2a797a92b",
   "metadata": {},
   "source": [
    "# 비선형회귀(경사하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8b3e9-fec8-4a04-8ec2-2bc555e0aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산을 위한 형변환(Pandas Series => np.array)\n",
    "X = np.array(df['x']).reshape(-1, 1)\n",
    "y = np.array(df['y']).reshape(-1, 1)\n",
    "xp = np.arange(-4.5, 4.5, 0.01).reshape(-1, 1)\n",
    "# print(X, type(X), end = '\\n\\n')\n",
    "# print(y, type(y))\n",
    "\n",
    "# 그래프 구역 나기기\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# 학습률, 에포크, 데이터 개수 할당\n",
    "lr = 0.001\n",
    "epoch = 500\n",
    "n = float(len(X))\n",
    "\n",
    "# 2차 ~ 4차를 구하기 위해 반복문\n",
    "for degree in range(2, 5):\n",
    "    w = np.zeros((degree + 1, 1)) # 차수 + 1만큼의 가중치가 생기므로 degree + 1개의 0을 w에 할당\n",
    "    A = np.hstack([X ** j for j in range(degree + 1)]) # X에 차수를 반영한 행렬 생성\n",
    "    for _ in range(epoch): # epoch만큼 반복 실행\n",
    "        y_pred = A @ w # 내적을 통해 예측함수 생성\n",
    "        polybasis = np.hstack([xp ** j for j in range(degree + 1)]) \n",
    "        w -= lr * (1 / n) * (A.T @ (y_pred - y)) # 경사하강법\n",
    "    print(f\"{degree}차 파라미터 : {w}\", end = '\\n\\n')\n",
    "    yp = polybasis @ w # 예측된 값\n",
    "\n",
    "    # 시각화\n",
    "    ax = axes[degree - 2]\n",
    "    ax.scatter(X, y, label='Training Data')\n",
    "    ax.plot(xp, yp, 'r',label= 'Predict Data')\n",
    "    ax.set_xlim(-2, 1)    \n",
    "    ax.set_ylim(-30, 20)\n",
    "    ax.set_title(f'Degree {degree}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.grid(alpha=0.4)\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6080a3-4d96-431e-bfec-3bb212a0593b",
   "metadata": {},
   "source": [
    "# 경사하강법(규제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7d0146-2bf3-4f15-b3a0-2a29f464c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"lr_data.csv\")\n",
    "data.head()\n",
    "\n",
    "X = np.array(data['x']).reshape(-1, 1)\n",
    "y = np.array(data['y']).reshape(-1, 1)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "w = np.zeros([2, 1]) # 2, 1\n",
    "m = len(X)\n",
    "\n",
    "A = np.hstack([X**0, X]) # 15, 2\n",
    "X = np.asmatrix(X)\n",
    "y = np.asmatrix(y)\n",
    "\n",
    "epoch = 1000\n",
    "lr = 0.01\n",
    "lam = 0.1\n",
    "\n",
    "for _ in range(epoch):\n",
    "    y_pred = A @ w                    \n",
    "    error = y_pred - y                  \n",
    "    grad = (1/m) * (A.T @ error)      # MSE에 대한 gradient\n",
    "    # subgrad = np.sign(w)               # L1 norm의 서브그래디언트\n",
    "    subgrad = 2 * lam * w              # L2 norm의 서브그래디언트\n",
    "    w = w - lr * (grad + lam * subgrad) # Lasso GD 업데이트\n",
    "\n",
    "print(w)\n",
    "xp = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "\n",
    "yp = w[0, 0] + w[1, 0] * xp\n",
    "plt.plot(X, y, 'bo')\n",
    "plt.plot(xp, yp, color='red', linewidth=2, label='Lasso Regression')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Lasso Regression (Gradient Descent)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.stem(range(len(w)), w)\n",
    "plt.xlabel(\"Weight Index\")\n",
    "plt.ylabel(\"Weight Value\")\n",
    "plt.title(\"Weights (w) from Gradient Descent\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
